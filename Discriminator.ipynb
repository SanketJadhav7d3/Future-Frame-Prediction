{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f02a84f-860e-4c14-9991-f5ba2aebd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c405f626-dc7b-443e-9b44-ebc0456d7a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FrameDiscriminator(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_unit: int, blocks: int, increment: int = 1):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=4, stride=2),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        # Create sequential blocks\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for i in range(blocks):\n",
    "            # Calculate input and output channels for each block\n",
    "            out_channels = hidden_units * (2 ** (increment + i))\n",
    "            in_channels = hidden_units if i == 0 else hidden_units * (2 ** (increment + i - 1))\n",
    "            self.blocks.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=4, stride=2),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            ))\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units * (2 ** (increment + blocks - 1)), out_channels=output_unit, kernel_size=4, stride=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=3*3,out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "Frame_model = FrameDiscriminator(input_shape=3, hidden_units=64, output_unit=1, blocks=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6333c669-f42d-4bfd-8b0b-4ad5cfa2b7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrameDiscriminator(\n",
       "  (input_layer): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Sequential(\n",
       "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=9, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Frame_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba085d47-9eed-4958-8be1-b2f669cdfe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDescriminator(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_unit: int, blocks: int, increment: int = 1):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1,padding=1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        # Create sequential blocks\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for i in range(blocks):\n",
    "            # Calculate input and output channels for each block\n",
    "            out_channels = hidden_units * (2 ** (increment + i))\n",
    "            in_channels = hidden_units if i == 0 else hidden_units * (2 ** (increment + i - 1))\n",
    "            self.blocks.append(nn.Sequential(\n",
    "                nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1,padding=1),\n",
    "                nn.BatchNorm3d(out_channels),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            ))\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=hidden_units * (2 ** (increment + blocks - 1)), out_channels=output_unit, kernel_size=3, stride=1,padding=0),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=3*126*126,out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        # print('After input layer:', x.shape)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            # print('After block:', x.shape)\n",
    "        x = self.output_layer(x)\n",
    "        # print('After output layer:', x.shape)\n",
    "        return x\n",
    "\n",
    "Sequence_Model = SequenceDescriminator(input_shape=3,hidden_units=64,output_unit=1,blocks=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59b7889e-3613-4224-a01e-67a6ed5d8846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceDescriminator(\n",
       "  (input_layer): Sequential(\n",
       "    (0): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Sequential(\n",
       "    (0): Conv3d(512, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=47628, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sequence_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fa11898-4478-417e-af23-bc05fc388906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvLSTM2DCell(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size, bias=True):\n",
    "        super(ConvLSTM2DCell, self).__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=self.input_channels + self.hidden_channels,\n",
    "            out_channels=4 * self.hidden_channels,\n",
    "            kernel_size=self.kernel_size,\n",
    "            padding=self.padding,\n",
    "            bias=self.bias\n",
    "        )\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        combined = torch.cat([x, h], dim=1)\n",
    "        conv_out = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(conv_out, self.hidden_channels, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "class ConvLSTM2D(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size, num_layers, bias=True, batch_first=False):\n",
    "        super(ConvLSTM2D, self).__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        self.cells = nn.ModuleList(\n",
    "            [ConvLSTM2DCell(self.input_channels if i == 0 else self.hidden_channels[i - 1],\n",
    "                            self.hidden_channels[i],\n",
    "                            self.kernel_size,\n",
    "                            self.bias) for i in range(self.num_layers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hidden_state=None):\n",
    "        if not self.batch_first:\n",
    "            x = x.permute(1, 0, 2, 3, 4)  # change to (time, batch, channel, height, width)\n",
    "\n",
    "        b, _, _, h, w = x.size()\n",
    "\n",
    "        if hidden_state is None:\n",
    "            hidden_state = self._init_hidden(b, h, w)\n",
    "\n",
    "        seq_len = x.size(1)\n",
    "        cur_layer_input = x\n",
    "\n",
    "        outputs = []\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h, c = self.cells[layer_idx](cur_layer_input[:, t, :, :, :], h, c)\n",
    "                output_inner.append(h)\n",
    "            cur_layer_input = torch.stack(output_inner, dim=1)\n",
    "            outputs.append(cur_layer_input)\n",
    "\n",
    "        return outputs, (h, c)\n",
    "\n",
    "    def _init_hidden(self, batch_size, height, width):\n",
    "        return [(torch.zeros(batch_size, hidden_dim, height, width, device=self.cells[0].conv.weight.device),\n",
    "                 torch.zeros(batch_size, hidden_dim, height, width, device=self.cells[0].conv.weight.device))\n",
    "                for hidden_dim in self.hidden_channels]\n",
    "\n",
    "class LSTMSequenceDiscriminator(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_unit: int, blocks: int, increment: int = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input layer\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        # Create ConvLSTM2D blocks\n",
    "        self.convlstm_blocks = nn.ModuleList()\n",
    "        for i in range(blocks):\n",
    "            out_channels = hidden_units * (2 ** (increment + i))\n",
    "            in_channels = hidden_units if i == 0 else hidden_units * (2 ** (increment + i - 1))\n",
    "            self.convlstm_blocks.append(nn.ModuleList([\n",
    "                ConvLSTM2D(input_channels=in_channels, hidden_channels=[out_channels], kernel_size=3, num_layers=1, batch_first=True),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            ]))\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units * (2 ** (increment + blocks - 1)), out_channels=output_unit, kernel_size=4, stride=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x should have shape (batch, time, channels, height, width)\n",
    "        batch_size, seq_len, _, height, width = x.size()\n",
    "\n",
    "        # Apply the initial convolution layer\n",
    "        x = x.view(-1, x.size(2), x.size(3), x.size(4))  # Merge batch and time\n",
    "        x = self.input_layer(x)\n",
    "        x = x.view(batch_size, seq_len, x.size(1), x.size(2), x.size(3))  # Reshape back to 5D\n",
    "\n",
    "        for block in self.convlstm_blocks:\n",
    "            conv_lstm, batch_norm, leaky_relu = block\n",
    "            x, _ = conv_lstm(x)  # Extract the sequence output from ConvLSTM2D\n",
    "\n",
    "            # Ensure x is a tensor before applying batch normalization\n",
    "            if isinstance(x, tuple):\n",
    "                x = x[0]  # Get the tensor from the tuple\n",
    "\n",
    "            # Apply BatchNorm2d to each time step\n",
    "            # Assuming x is now a 5D tensor of shape (batch, time, channels, height, width)\n",
    "            x = torch.stack([batch_norm(t) for t in x.unbind(dim=1)], dim=1)  # Apply BatchNorm2d per time step\n",
    "            x = leaky_relu(x)  # Apply LeakyReLU\n",
    "\n",
    "        # Use the last time step's output\n",
    "        last_output = x[:, -1, :, :, :]\n",
    "        out = self.output_layer(last_output)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "LSTM_Sequence_Model = LSTMSequenceDiscriminator(input_shape=3, hidden_units=64, output_unit=1, blocks=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c35c810-c030-4db5-9b92-c2b727649fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMSequenceDiscriminator(\n",
       "  (input_layer): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (convlstm_blocks): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): ConvLSTM2D(\n",
       "        (cells): ModuleList(\n",
       "          (0): ConvLSTM2DCell(\n",
       "            (conv): Conv2d(192, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): ConvLSTM2D(\n",
       "        (cells): ModuleList(\n",
       "          (0): ConvLSTM2DCell(\n",
       "            (conv): Conv2d(384, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): ConvLSTM2D(\n",
       "        (cells): ModuleList(\n",
       "          (0): ConvLSTM2DCell(\n",
       "            (conv): Conv2d(768, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Sequential(\n",
       "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_Sequence_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "760e89aa-f338-4268-8e77-69c0a6c5360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After input layer: torch.Size([1, 64, 5, 128, 128])\n",
      "After block: torch.Size([1, 128, 5, 128, 128])\n",
      "After block: torch.Size([1, 256, 5, 128, 128])\n",
      "After block: torch.Size([1, 512, 5, 128, 128])\n",
      "After output layer: torch.Size([1, 1])\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 5  # Sequence length (depth)\n",
    "channels = 3  # RGB channels\n",
    "height = 128\n",
    "width = 128\n",
    "\n",
    "# Example tensor with random values\n",
    "x = torch.rand(batch_size, channels,seq_len,height, width)  # Note the order: [batch, channels, depth, height, width]\n",
    "\n",
    "# Forward pass\n",
    "output = Sequence_Model(x)\n",
    "print(torch.round(output).item())  # Print the output s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9a3ec8c-f4bf-415c-84e5-9b538e6d797c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size, stride=1, padding=1):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        \n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=input_channels + hidden_channels,\n",
    "            out_channels=4 * hidden_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        h, c = hidden\n",
    "        \n",
    "        # Ensure that x and h have the same spatial dimensions\n",
    "        if x.size()[2:] != h.size()[2:]:\n",
    "            raise ValueError(f\"Spatial dimensions of x {x.size()[2:]} and h {h.size()[2:]} must match.\")\n",
    "        \n",
    "        combined = torch.cat([x, h], dim=1)\n",
    "        conv_out = self.conv(combined)\n",
    "        \n",
    "        i, f, o, g = torch.chunk(conv_out, 4, dim=1)\n",
    "        i = torch.sigmoid(i)\n",
    "        f = torch.sigmoid(f)\n",
    "        o = torch.sigmoid(o)\n",
    "        g = torch.tanh(g)\n",
    "        \n",
    "        c = f * c + i * g\n",
    "        h = o * torch.tanh(c)\n",
    "        \n",
    "        return h, c\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size, num_layers):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.cells = nn.ModuleList([\n",
    "            ConvLSTMCell(input_channels if i == 0 else hidden_channels,\n",
    "                         hidden_channels,\n",
    "                         kernel_size)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _, height, width = x.size()\n",
    "        hidden = [(torch.zeros(batch_size, self.cells[0].hidden_channels, height, width).to(x.device),\n",
    "                   torch.zeros(batch_size, self.cells[0].hidden_channels, height, width).to(x.device))\n",
    "                  for _ in range(self.num_layers)]\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            for l in range(self.num_layers):\n",
    "                hidden[l] = self.cells[l](x[:, t], hidden[l])\n",
    "                \n",
    "        return hidden[-1][0]  # Output of the last layer's hidden state\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_channels = 1\n",
    "    hidden_channels = 16\n",
    "    kernel_size = 3\n",
    "    num_layers = 1\n",
    "    seq_len = 5\n",
    "    height, width = 64, 64\n",
    "    \n",
    "    model = ConvLSTM(input_channels, hidden_channels, kernel_size, num_layers)\n",
    "    input_tensor = torch.randn(8, seq_len, input_channels, height, width)  # Batch size of 8\n",
    "    output = model(input_tensor)\n",
    "    print(output.shape)  # Expected output shape: (8, hidden_channels, height, width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c669b9c-23ae-4876-a3a6-71648e86f874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
